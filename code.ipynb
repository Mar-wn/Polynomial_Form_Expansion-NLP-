{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iqaOkOdzmWp"
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsmCnH6dfNXX",
    "outputId": "e8866a9b-a8ef-4990-90db-7ad6b64fb4fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "\n",
    "with open('dataset.txt') as file:\n",
    "    \n",
    "    equations = file.read().splitlines()\n",
    "\n",
    "len(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvDtTMOEfNXf",
    "outputId": "e300fa44-e5d0-43cf-b178-73e48ee8787a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for repeated equations\n",
    "\n",
    "len(equations) == len(set(equations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cA-pyf_0fNXh",
    "outputId": "25dc1f43-d121-4ac8-fddb-72cad4387a81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "732171"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only unique equations\n",
    "\n",
    "equations = list(set(equations))\n",
    "\n",
    "len(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8J_B37BfNXj",
    "outputId": "afaa18e8-31fa-4266-cc97-7922fbf4c6a1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(-9*h-13)*(h+4)=-9*h**2-49*h-52',\n",
       " '(2*i-8)*(5*i-25)=10*i**2-90*i+200',\n",
       " '(-8*t-4)*(8*t+13)=-64*t**2-136*t-52',\n",
       " '(1-8*y)*(6*y-1)=-48*y**2+14*y-1',\n",
       " '(s+11)*(4*s-20)=4*s**2+24*s-220',\n",
       " '(24-i)*(8*i+29)=-8*i**2+163*i+696',\n",
       " '(z+24)*(7*z-12)=7*z**2+156*z-288',\n",
       " '(-7*z-9)*(-2*z-12)=14*z**2+102*z+108',\n",
       " '(10-9*j)*(-8*j-28)=72*j**2+172*j-280',\n",
       " '(17-2*s)*(5*s-4)=-10*s**2+93*s-68']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see some examples\n",
    "\n",
    "equations[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cQ3yNDgfNXj"
   },
   "outputs": [],
   "source": [
    "# check that the '=' sign is present in ALL equations and just once\n",
    "\n",
    "for equation in equations:\n",
    "    \n",
    "    assert(equation.count('=') == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrxbhiwufNXk",
    "outputId": "75573671-7c53-42d8-a98e-60f4bba4f98e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              input (factored)  |  output (expanded)             \n",
      "-----------------------------------------------------------------\n",
      "                  -3*k*(2*k-4)  =  -6*k**2+12*k                  \n",
      "               (x+16)*(2*x+24)  =  2*x**2+56*x+384               \n",
      "                   -5*i*(15-i)  =  5*i**2-75*i                   \n",
      "               (6-2*h)*(2*h+3)  =  -4*h**2+6*h+18                \n",
      "                 (t-1)*(3*t+5)  =  3*t**2+2*t-5                  \n",
      "                (6-j)*(8*j+25)  =  -8*j**2+23*j+150              \n",
      "                 -6*t*(13-7*t)  =  42*t**2-78*t                  \n",
      "               (30-4*j)*(j+29)  =  -4*j**2-86*j+870              \n",
      "                   7*k*(7*k+3)  =  49*k**2+21*k                  \n",
      "              (5*a+8)*(6*a-15)  =  30*a**2-27*a-120              \n"
     ]
    }
   ],
   "source": [
    "# split equations into factorized and expanded forms\n",
    "\n",
    "pairs = [equation.lower().split('=') for equation in equations] # we first lowercase all of the equations\n",
    "\n",
    "factorized = [pair[0] for pair in pairs]\n",
    "\n",
    "expanded = [pair[1] for pair in pairs]\n",
    "\n",
    "# see some examples\n",
    "\n",
    "print(f\"{'input (factored)':>30}  |  {'output (expanded)':30}\")\n",
    "print(\"-\"*(30*2+5))\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    print(f\"{factorized[i]:>30}  =  {expanded[i]:30}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "YQFL6bWUfNXm"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def find_and_count(pattern, string):\n",
    "    \n",
    "    \"\"\"\n",
    "    Looks for 'pattern' in 'string', counts its occurences and sorts them\n",
    "    Returns: a sorted list of found patterns and their counts\n",
    "    \"\"\"\n",
    "\n",
    "    return Counter(re.findall(pattern, string)).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIOZFafifNXo",
    "outputId": "b5b4434f-cf8b-452a-cda9-e091944f9818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# look for white spaces\n",
    "\n",
    "print(find_and_count(' ', ''.join(factorized)))\n",
    "print(find_and_count(' ', ''.join(expanded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYocfxIlfNXp",
    "outputId": "1d52db63-aea5-47d3-c612-c090ce7d8dce",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2', 711436),\n",
       " ('1', 582600),\n",
       " ('3', 377158),\n",
       " ('8', 272743),\n",
       " ('5', 272671),\n",
       " ('6', 272624),\n",
       " ('4', 272374),\n",
       " ('7', 271962),\n",
       " ('9', 198703),\n",
       " ('0', 124914)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for digits\n",
    "\n",
    "find_and_count('\\d', ''.join(factorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqScV5xOfNXq",
    "outputId": "1d8abdde-4750-438c-b563-ec4f2a428d04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2', 1401762),\n",
       " ('1', 687712),\n",
       " ('4', 505159),\n",
       " ('6', 423616),\n",
       " ('3', 397345),\n",
       " ('0', 393811),\n",
       " ('5', 381294),\n",
       " ('8', 377866),\n",
       " ('7', 254089),\n",
       " ('9', 210588)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_and_count('\\d', ''.join(expanded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sAjkwzuufNXr",
    "outputId": "c163dd76-bb89-4299-e205-aeee7b3368b2",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 170150),\n",
       " ('i', 169508),\n",
       " ('n', 169274),\n",
       " ('t', 95734),\n",
       " ('k', 95512),\n",
       " ('y', 95491),\n",
       " ('c', 95461),\n",
       " ('a', 95417),\n",
       " ('z', 95358),\n",
       " ('o', 95166),\n",
       " ('j', 95148),\n",
       " ('x', 94849),\n",
       " ('h', 94694),\n",
       " ('cos', 19439),\n",
       " ('sin', 19417),\n",
       " ('tan', 19361)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for letters sequences\n",
    "\n",
    "find_and_count('[a-z]+', ''.join(factorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L51HjkeKfNXr",
    "outputId": "8db8732a-546d-4537-9fda-e1b87d80cb25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 169013),\n",
       " ('i', 168348),\n",
       " ('n', 168139),\n",
       " ('t', 94946),\n",
       " ('y', 94711),\n",
       " ('k', 94695),\n",
       " ('c', 94658),\n",
       " ('a', 94619),\n",
       " ('z', 94604),\n",
       " ('o', 94369),\n",
       " ('j', 94366),\n",
       " ('x', 94063),\n",
       " ('h', 93900),\n",
       " ('cos', 19305),\n",
       " ('sin', 19265),\n",
       " ('tan', 19226),\n",
       " ('ii', 48),\n",
       " ('sn', 48),\n",
       " ('nn', 47),\n",
       " ('so', 47),\n",
       " ('in', 46),\n",
       " ('ij', 44),\n",
       " ('xs', 43),\n",
       " ('is', 42),\n",
       " ('ns', 40),\n",
       " ('cn', 39),\n",
       " ('ic', 39),\n",
       " ('yi', 37),\n",
       " ('ni', 36),\n",
       " ('ci', 36),\n",
       " ('it', 36),\n",
       " ('ss', 35),\n",
       " ('ck', 34),\n",
       " ('kn', 34),\n",
       " ('sa', 34),\n",
       " ('si', 34),\n",
       " ('nz', 33),\n",
       " ('nk', 33),\n",
       " ('ti', 33),\n",
       " ('ks', 33),\n",
       " ('sh', 33),\n",
       " ('jn', 33),\n",
       " ('sx', 32),\n",
       " ('zn', 32),\n",
       " ('ix', 32),\n",
       " ('ts', 32),\n",
       " ('sc', 31),\n",
       " ('at', 31),\n",
       " ('ka', 31),\n",
       " ('hs', 31),\n",
       " ('kk', 31),\n",
       " ('xi', 31),\n",
       " ('ct', 31),\n",
       " ('nh', 30),\n",
       " ('ny', 30),\n",
       " ('sy', 30),\n",
       " ('ky', 30),\n",
       " ('sz', 30),\n",
       " ('js', 29),\n",
       " ('no', 29),\n",
       " ('ok', 29),\n",
       " ('yn', 29),\n",
       " ('nj', 29),\n",
       " ('ki', 29),\n",
       " ('xj', 29),\n",
       " ('ji', 29),\n",
       " ('xz', 29),\n",
       " ('oi', 29),\n",
       " ('tn', 28),\n",
       " ('jo', 28),\n",
       " ('oh', 28),\n",
       " ('nx', 28),\n",
       " ('os', 28),\n",
       " ('xh', 28),\n",
       " ('ah', 28),\n",
       " ('kc', 28),\n",
       " ('ay', 28),\n",
       " ('iz', 27),\n",
       " ('tz', 27),\n",
       " ('cx', 27),\n",
       " ('xo', 27),\n",
       " ('kz', 27),\n",
       " ('kt', 27),\n",
       " ('an', 27),\n",
       " ('ca', 27),\n",
       " ('ik', 26),\n",
       " ('xx', 26),\n",
       " ('oy', 26),\n",
       " ('xa', 26),\n",
       " ('iy', 26),\n",
       " ('as', 26),\n",
       " ('ox', 26),\n",
       " ('ch', 26),\n",
       " ('st', 26),\n",
       " ('hi', 26),\n",
       " ('ia', 26),\n",
       " ('cz', 25),\n",
       " ('sk', 25),\n",
       " ('zs', 25),\n",
       " ('jy', 25),\n",
       " ('io', 25),\n",
       " ('nc', 25),\n",
       " ('ai', 25),\n",
       " ('tj', 25),\n",
       " ('sj', 25),\n",
       " ('ak', 24),\n",
       " ('ih', 24),\n",
       " ('na', 24),\n",
       " ('cs', 24),\n",
       " ('tt', 24),\n",
       " ('oo', 24),\n",
       " ('ko', 24),\n",
       " ('oa', 24),\n",
       " ('cj', 24),\n",
       " ('zy', 24),\n",
       " ('hn', 24),\n",
       " ('zt', 23),\n",
       " ('hh', 23),\n",
       " ('ta', 23),\n",
       " ('yo', 23),\n",
       " ('zz', 23),\n",
       " ('zk', 23),\n",
       " ('hk', 23),\n",
       " ('hy', 23),\n",
       " ('xk', 22),\n",
       " ('zx', 22),\n",
       " ('to', 22),\n",
       " ('hx', 22),\n",
       " ('tx', 22),\n",
       " ('zi', 22),\n",
       " ('jt', 22),\n",
       " ('zo', 22),\n",
       " ('ys', 22),\n",
       " ('jh', 22),\n",
       " ('aj', 22),\n",
       " ('ao', 22),\n",
       " ('yc', 22),\n",
       " ('hj', 22),\n",
       " ('ht', 21),\n",
       " ('ho', 21),\n",
       " ('hz', 21),\n",
       " ('cc', 21),\n",
       " ('on', 21),\n",
       " ('hc', 21),\n",
       " ('xc', 21),\n",
       " ('oz', 21),\n",
       " ('zj', 21),\n",
       " ('cy', 21),\n",
       " ('ja', 21),\n",
       " ('yk', 20),\n",
       " ('tc', 20),\n",
       " ('az', 20),\n",
       " ('oj', 20),\n",
       " ('xn', 20),\n",
       " ('jc', 20),\n",
       " ('ax', 20),\n",
       " ('yt', 20),\n",
       " ('zh', 19),\n",
       " ('ot', 19),\n",
       " ('nt', 19),\n",
       " ('ty', 19),\n",
       " ('tk', 19),\n",
       " ('yy', 19),\n",
       " ('yx', 19),\n",
       " ('ac', 19),\n",
       " ('zc', 19),\n",
       " ('xy', 19),\n",
       " ('yh', 19),\n",
       " ('th', 19),\n",
       " ('ha', 18),\n",
       " ('jk', 18),\n",
       " ('co', 18),\n",
       " ('za', 18),\n",
       " ('oc', 17),\n",
       " ('ya', 17),\n",
       " ('ntan', 17),\n",
       " ('jz', 17),\n",
       " ('jx', 16),\n",
       " ('aa', 16),\n",
       " ('ycos', 16),\n",
       " ('ssin', 16),\n",
       " ('itan', 16),\n",
       " ('kh', 15),\n",
       " ('yz', 15),\n",
       " ('kj', 14),\n",
       " ('jj', 14),\n",
       " ('asin', 14),\n",
       " ('xt', 14),\n",
       " ('xtan', 13),\n",
       " ('kx', 13),\n",
       " ('yj', 13),\n",
       " ('jsin', 12),\n",
       " ('ccos', 12),\n",
       " ('xsin', 12),\n",
       " ('ytan', 11),\n",
       " ('stan', 11),\n",
       " ('hsin', 10),\n",
       " ('scos', 9),\n",
       " ('isin', 9),\n",
       " ('ocos', 9),\n",
       " ('csin', 9),\n",
       " ('ncos', 9),\n",
       " ('atan', 9),\n",
       " ('jcos', 9),\n",
       " ('icos', 8),\n",
       " ('tcos', 8),\n",
       " ('jtan', 8),\n",
       " ('zcos', 8),\n",
       " ('ttan', 8),\n",
       " ('ztan', 7),\n",
       " ('tsin', 7),\n",
       " ('nsin', 7),\n",
       " ('hcos', 7),\n",
       " ('htan', 7),\n",
       " ('ksin', 7),\n",
       " ('zsin', 7),\n",
       " ('xcos', 6),\n",
       " ('ysin', 6),\n",
       " ('acos', 6),\n",
       " ('kcos', 5),\n",
       " ('ktan', 5),\n",
       " ('ctan', 4),\n",
       " ('otan', 4),\n",
       " ('osin', 4)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_and_count('[a-z]+', ''.join(expanded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rjsBvYQfNXs",
    "outputId": "1293f5c0-35fc-42f1-b8ce-b8d4f0bd771f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('*', 1103643),\n",
       " ('-', 930174),\n",
       " (')*(', 488639),\n",
       " (')(', 403116),\n",
       " ('+', 340905),\n",
       " (')(-', 175477),\n",
       " ('*(', 110451),\n",
       " (')-', 100873),\n",
       " (')*(-', 82353),\n",
       " (')', 73234),\n",
       " ('(', 59630),\n",
       " ('*(-', 38215),\n",
       " (')+', 13440),\n",
       " (')*', 7543),\n",
       " ('))*(', 5516),\n",
       " ('))*', 1940),\n",
       " ('))*(-', 1727),\n",
       " (')**', 1653),\n",
       " ('**', 923),\n",
       " ('(-', 618),\n",
       " ('))(', 457),\n",
       " (')-(', 339),\n",
       " ('))(-', 200),\n",
       " ('))-', 112),\n",
       " (')-(-', 99),\n",
       " ('))', 80),\n",
       " ('))**', 4),\n",
       " ('-(', 1)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for non-alphanumeric sequences\n",
    "\n",
    "find_and_count('\\W+', ''.join(factorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZ27gzrnfNXs",
    "outputId": "5783bd74-341e-4957-ef0a-9132907ac6fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('*', 1416884),\n",
       " ('-', 1005050),\n",
       " ('**', 702623),\n",
       " ('+', 642639),\n",
       " ('(', 58148),\n",
       " (')**', 29548),\n",
       " (')-', 14230),\n",
       " (')+', 9630),\n",
       " (')', 4740)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_and_count('\\W+', ''.join(expanded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_zvFPfZfNXt"
   },
   "source": [
    "For both factorized and expanded 'languages', we choose vocabs made of:\n",
    "\n",
    "* **digits**: from 0 to 9\n",
    "* **letters sequences**: variables and found trigonometric functions \n",
    "* **non-alphanumeric sequences**: math operators and the '(' ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "e2bydilGfNXv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab_pattern = '\\d|[a-z]+|\\(|\\)|\\+|-|\\*+'\n",
    "\n",
    "def create_vocab(data, vocab_pattern, threshold):\n",
    "  \"\"\"\n",
    "  Extracts vocab items from data following a vocab_pattern, omitting items with a frequency less than threshold.\n",
    "  Returns: a vocab list\n",
    "  \"\"\"\n",
    "  vocab = [item for item, freq in find_and_count(vocab_pattern, data) if freq > threshold]\n",
    "\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpypfQ5oa-dQ",
    "outputId": "f87e8652-e73f-49d4-9000-bd868225d4b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['*',\n",
       " '(',\n",
       " ')',\n",
       " '-',\n",
       " '2',\n",
       " '1',\n",
       " '3',\n",
       " '+',\n",
       " '8',\n",
       " '5',\n",
       " '6',\n",
       " '4',\n",
       " '7',\n",
       " '9',\n",
       " 's',\n",
       " 'i',\n",
       " 'n',\n",
       " '0',\n",
       " 't',\n",
       " 'k',\n",
       " 'y',\n",
       " 'c',\n",
       " 'a',\n",
       " 'z',\n",
       " 'o',\n",
       " 'j',\n",
       " 'x',\n",
       " 'h',\n",
       " 'cos',\n",
       " 'sin',\n",
       " 'tan',\n",
       " '**']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create vocabs for both factorized and expanded languages\n",
    "\n",
    "factorized_vocab = create_vocab(''.join(factorized), vocab_pattern, 1000)\n",
    "\n",
    "factorized_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GcKYW2RkfNXw",
    "outputId": "12171c5f-1794-49d9-c6a7-229c585ab9bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(factorized_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CP7XX2y0fNXw",
    "outputId": "b0bfb3e6-273f-46ae-c131-b43be81c9880",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['*',\n",
       " '2',\n",
       " '-',\n",
       " '**',\n",
       " '1',\n",
       " '+',\n",
       " '4',\n",
       " '6',\n",
       " '3',\n",
       " '0',\n",
       " '5',\n",
       " '8',\n",
       " '7',\n",
       " '9',\n",
       " 's',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " 'k',\n",
       " 'c',\n",
       " 'y',\n",
       " 'z',\n",
       " 'a',\n",
       " 'o',\n",
       " 'j',\n",
       " 'x',\n",
       " 'h',\n",
       " '(',\n",
       " ')',\n",
       " 'cos',\n",
       " 'sin',\n",
       " 'tan']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_vocab = create_vocab(''.join(expanded), vocab_pattern, 1000)\n",
    "\n",
    "expanded_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKndw8r2fNXx",
    "outputId": "1c4c0bbc-84f6-4518-bca7-ac382c86247e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(factorized_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "460c12WdfNXy",
    "outputId": "9b9fd28c-bf39-4454-c296-185c31442df0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is it the same vocab?\n",
    "\n",
    "factorized_vocab.sort() == expanded_vocab.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "hTa6oRkDfNXy"
   },
   "outputs": [],
   "source": [
    "# as it turns out that both type of forms generated the same vocab, we will be using just one\n",
    "\n",
    "vocab = expanded_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "rP4AO1kXfNXz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add a padding item to the vocab to prepare for a padding operation\n",
    "\n",
    "vocab.append('<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDTRxb69NHM5",
    "outputId": "a93756d2-37f3-4f8c-b2d3-6f17439fe1f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['*',\n",
       " '2',\n",
       " '-',\n",
       " '**',\n",
       " '1',\n",
       " '+',\n",
       " '4',\n",
       " '6',\n",
       " '3',\n",
       " '0',\n",
       " '5',\n",
       " '8',\n",
       " '7',\n",
       " '9',\n",
       " 's',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " 'k',\n",
       " 'c',\n",
       " 'y',\n",
       " 'z',\n",
       " 'a',\n",
       " 'o',\n",
       " 'j',\n",
       " 'x',\n",
       " 'h',\n",
       " '(',\n",
       " ')',\n",
       " 'cos',\n",
       " 'sin',\n",
       " 'tan',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "2ErTdrhsfNXz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a vocab dict and an inverted vocab dict to map between vocab items and vocab indexes\n",
    "\n",
    "vocab_dict = {item:index for index, item in enumerate(vocab)}\n",
    "\n",
    "inver_vocab_dict = {index:item for index, item in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBEHHhr50E6e"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "M5TLDtGffNXz"
   },
   "outputs": [],
   "source": [
    "# filter into vocab\n",
    "\n",
    "vocab_pattern = '\\d|[a-z]|cos|sin|tan|\\(|\\)|\\+|-|\\*+'\n",
    "\n",
    "def format_forms(forms, vocab_pattern):\n",
    "  \"\"\"\n",
    "  Transforms each form of forms into items of a vocab defined by a vocab_pattern\n",
    "  Returns: a list of lists (found vocab items in the form)\n",
    "  \"\"\"\n",
    "\n",
    "  formatted_form = [re.findall(vocab_pattern, form) for form in forms]\n",
    "\n",
    "  return formatted_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VPiaSJ82esQB"
   },
   "outputs": [],
   "source": [
    "formatted_factorized = format_forms(factorized, vocab_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0EIj5LVgfNX0",
    "outputId": "c5edaa43-b7cf-46a4-e8f4-744fe2eaf9aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(', '-', '9', '*', 'h', '-', '1', '3', ')', '*', '(', 'h', '+', '4', ')']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_factorized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CwIzyJUGfNX0"
   },
   "outputs": [],
   "source": [
    "formatted_expanded = format_forms(expanded, vocab_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azdLfg30fNX0",
    "outputId": "e4588cda-6c12-425b-ace4-632940740163"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-', '9', '*', 'h', '**', '2', '-', '4', '9', '*', 'h', '-', '5', '2']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_expanded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2y12OT-fNX1",
    "outputId": "772f203c-6fc8-4665-91a9-c397a7c04513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum factorized forms length:  29\n",
      "maximum expanded forms length:  27\n"
     ]
    }
   ],
   "source": [
    "# examine maximum lengths in our formatted forms\n",
    "\n",
    "print('maximum factorized forms length: ', max([len(form) for form in formatted_factorized]))\n",
    "print('maximum expanded forms length: ',max([len(form) for form in formatted_expanded]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "W21cGaxD098n"
   },
   "outputs": [],
   "source": [
    "input_seq_len = max([len(form) for form in formatted_factorized])\n",
    "output_seq_len = max([len(form) for form in formatted_expanded])\n",
    "vocab_len = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "V-pmPvP0fNX1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pad the empty spots in forms with lengths < maximum length with a special item '<pad>'\n",
    "\n",
    "formatted_factorized = [ seq + ['<pad>'] * (input_seq_len - len(seq)) for seq in formatted_factorized]\n",
    "\n",
    "formatted_expanded = [ seq + ['<pad>'] * (output_seq_len - len(seq)) for seq in formatted_expanded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gw_SlDbefNX2"
   },
   "outputs": [],
   "source": [
    "# convert forms into numerical vectors of indexes in vocab\n",
    "\n",
    "X_indexed = [list(map(vocab_dict.get, form)) for form in formatted_factorized]\n",
    "Y_indexed = [list(map(vocab_dict.get, form)) for form in formatted_expanded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NFoTU1-lfNX3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "g6sVDKaBfNX3"
   },
   "outputs": [],
   "source": [
    "# convert indexes into one hot encoded vectors\n",
    "\n",
    "X = np.array(tf.one_hot(X_indexed, len(vocab)))\n",
    "Y = np.array(tf.one_hot(Y_indexed, len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8S-mlwvfNX4",
    "outputId": "d83681b5-74f1-4b54-a5be-853b12b283c8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695562, 29, 33)\n",
      "(36609, 29, 33)\n",
      "(695562, 27, 33)\n",
      "(36609, 27, 33)\n"
     ]
    }
   ],
   "source": [
    "# split data into test and train\n",
    "\n",
    "from sklearn import model_selection \n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size= 0.05)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXrCd0kX0Ov5"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "j-5-T3QK8AeQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Bidirectional, Concatenate, Dot, RepeatVector, Activation\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWhFSDN0qToz"
   },
   "outputs": [],
   "source": [
    "## build an encoder decoder with attention mechanism\n",
    "\n",
    "# define layers\n",
    "\n",
    "repeator = RepeatVector(input_seq_len)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation('softmax')\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HyfhpwdtJhe"
   },
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Calculates a context vector from the encoder states a and the decoder previous states s_prev\n",
    "    \"\"\"\n",
    "    \n",
    "    s_prev = repeator(s_prev)\n",
    "\n",
    "    # concatenate a and s_prev on the last axis\n",
    "    concat = concatenator([a, s_prev])\n",
    "\n",
    "    # propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e\n",
    "    e = densor1(concat)\n",
    "\n",
    "    # propagate e through a small fully-connected neural network to compute the \"energies\" variable energies\n",
    "    energies = densor2(e)\n",
    "\n",
    "    # compute the attention weights \"alphas\"\n",
    "    alphas = activator(energies)\n",
    "\n",
    "    # compute the context vector to be given to the decoder LSTM\n",
    "    context = dotor([alphas, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZgPNHXMb5uI9"
   },
   "outputs": [],
   "source": [
    "n_a = 32\n",
    "n_s = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b-O93xfw215"
   },
   "outputs": [],
   "source": [
    "# define decoder layers\n",
    "\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(vocab_len, activation= 'softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZIJgQ2myQ38"
   },
   "outputs": [],
   "source": [
    "def model(Tx, Ty, n_a, n_s, vocab_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    \n",
    "    Returns:\n",
    "    model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define inputs\n",
    "    X = Input(shape=(Tx, vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = []\n",
    "    \n",
    "    # Define pre-attention Bi-LSTM encoder\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences= True))(X)\n",
    "    \n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # Perform one step of the attention mechanism to get back the context vector at step t\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # Apply the post-attention LSTM to the \"context\" vector\n",
    "        s, _, c = post_activation_LSTM_cell(initial_state = [s,c], inputs= context)\n",
    "        \n",
    "        # Apply Dense layer to the hidden state output of the decoder\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Append \"out\" to the \"outputs\" list\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Create model instance taking three inputs and returning the list of outputs\n",
    "    model = Model(inputs= [X, s0, c0], outputs= outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4d1LXnKc0ofy"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = model(input_seq_len, output_seq_len, n_a, n_s, vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ky07KCEg07Sb",
    "outputId": "a5659db8-4a22-4dfd-a3e7-00735bf0e3bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 29, 33)]     0           []                               \n",
      "                                                                                                  \n",
      " s0 (InputLayer)                [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 29, 64)      16896       ['input_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 29, 64)       0           ['s0[0][0]',                     \n",
      "                                                                  'lstm[0][0]',                   \n",
      "                                                                  'lstm[1][0]',                   \n",
      "                                                                  'lstm[2][0]',                   \n",
      "                                                                  'lstm[3][0]',                   \n",
      "                                                                  'lstm[4][0]',                   \n",
      "                                                                  'lstm[5][0]',                   \n",
      "                                                                  'lstm[6][0]',                   \n",
      "                                                                  'lstm[7][0]',                   \n",
      "                                                                  'lstm[8][0]',                   \n",
      "                                                                  'lstm[9][0]',                   \n",
      "                                                                  'lstm[10][0]',                  \n",
      "                                                                  'lstm[11][0]',                  \n",
      "                                                                  'lstm[12][0]',                  \n",
      "                                                                  'lstm[13][0]',                  \n",
      "                                                                  'lstm[14][0]',                  \n",
      "                                                                  'lstm[15][0]',                  \n",
      "                                                                  'lstm[16][0]',                  \n",
      "                                                                  'lstm[17][0]',                  \n",
      "                                                                  'lstm[18][0]',                  \n",
      "                                                                  'lstm[19][0]',                  \n",
      "                                                                  'lstm[20][0]',                  \n",
      "                                                                  'lstm[21][0]',                  \n",
      "                                                                  'lstm[22][0]',                  \n",
      "                                                                  'lstm[23][0]',                  \n",
      "                                                                  'lstm[24][0]',                  \n",
      "                                                                  'lstm[25][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 29, 128)      0           ['bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[0][0]',          \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[1][0]',          \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[2][0]',          \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[3][0]',          \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[4][0]',          \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[5][0]',          \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[6][0]',          \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[7][0]',          \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[8][0]',          \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[9][0]',          \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[10][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[11][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[12][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[13][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[14][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[15][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[16][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[17][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[18][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[19][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[20][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[21][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[22][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[23][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[24][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[25][0]',         \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector[26][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 29, 10)       1290        ['concatenate[0][0]',            \n",
      "                                                                  'concatenate[1][0]',            \n",
      "                                                                  'concatenate[2][0]',            \n",
      "                                                                  'concatenate[3][0]',            \n",
      "                                                                  'concatenate[4][0]',            \n",
      "                                                                  'concatenate[5][0]',            \n",
      "                                                                  'concatenate[6][0]',            \n",
      "                                                                  'concatenate[7][0]',            \n",
      "                                                                  'concatenate[8][0]',            \n",
      "                                                                  'concatenate[9][0]',            \n",
      "                                                                  'concatenate[10][0]',           \n",
      "                                                                  'concatenate[11][0]',           \n",
      "                                                                  'concatenate[12][0]',           \n",
      "                                                                  'concatenate[13][0]',           \n",
      "                                                                  'concatenate[14][0]',           \n",
      "                                                                  'concatenate[15][0]',           \n",
      "                                                                  'concatenate[16][0]',           \n",
      "                                                                  'concatenate[17][0]',           \n",
      "                                                                  'concatenate[18][0]',           \n",
      "                                                                  'concatenate[19][0]',           \n",
      "                                                                  'concatenate[20][0]',           \n",
      "                                                                  'concatenate[21][0]',           \n",
      "                                                                  'concatenate[22][0]',           \n",
      "                                                                  'concatenate[23][0]',           \n",
      "                                                                  'concatenate[24][0]',           \n",
      "                                                                  'concatenate[25][0]',           \n",
      "                                                                  'concatenate[26][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 29, 1)        11          ['dense[0][0]',                  \n",
      "                                                                  'dense[1][0]',                  \n",
      "                                                                  'dense[2][0]',                  \n",
      "                                                                  'dense[3][0]',                  \n",
      "                                                                  'dense[4][0]',                  \n",
      "                                                                  'dense[5][0]',                  \n",
      "                                                                  'dense[6][0]',                  \n",
      "                                                                  'dense[7][0]',                  \n",
      "                                                                  'dense[8][0]',                  \n",
      "                                                                  'dense[9][0]',                  \n",
      "                                                                  'dense[10][0]',                 \n",
      "                                                                  'dense[11][0]',                 \n",
      "                                                                  'dense[12][0]',                 \n",
      "                                                                  'dense[13][0]',                 \n",
      "                                                                  'dense[14][0]',                 \n",
      "                                                                  'dense[15][0]',                 \n",
      "                                                                  'dense[16][0]',                 \n",
      "                                                                  'dense[17][0]',                 \n",
      "                                                                  'dense[18][0]',                 \n",
      "                                                                  'dense[19][0]',                 \n",
      "                                                                  'dense[20][0]',                 \n",
      "                                                                  'dense[21][0]',                 \n",
      "                                                                  'dense[22][0]',                 \n",
      "                                                                  'dense[23][0]',                 \n",
      "                                                                  'dense[24][0]',                 \n",
      "                                                                  'dense[25][0]',                 \n",
      "                                                                  'dense[26][0]']                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 29, 1)        0           ['dense_1[0][0]',                \n",
      "                                                                  'dense_1[1][0]',                \n",
      "                                                                  'dense_1[2][0]',                \n",
      "                                                                  'dense_1[3][0]',                \n",
      "                                                                  'dense_1[4][0]',                \n",
      "                                                                  'dense_1[5][0]',                \n",
      "                                                                  'dense_1[6][0]',                \n",
      "                                                                  'dense_1[7][0]',                \n",
      "                                                                  'dense_1[8][0]',                \n",
      "                                                                  'dense_1[9][0]',                \n",
      "                                                                  'dense_1[10][0]',               \n",
      "                                                                  'dense_1[11][0]',               \n",
      "                                                                  'dense_1[12][0]',               \n",
      "                                                                  'dense_1[13][0]',               \n",
      "                                                                  'dense_1[14][0]',               \n",
      "                                                                  'dense_1[15][0]',               \n",
      "                                                                  'dense_1[16][0]',               \n",
      "                                                                  'dense_1[17][0]',               \n",
      "                                                                  'dense_1[18][0]',               \n",
      "                                                                  'dense_1[19][0]',               \n",
      "                                                                  'dense_1[20][0]',               \n",
      "                                                                  'dense_1[21][0]',               \n",
      "                                                                  'dense_1[22][0]',               \n",
      "                                                                  'dense_1[23][0]',               \n",
      "                                                                  'dense_1[24][0]',               \n",
      "                                                                  'dense_1[25][0]',               \n",
      "                                                                  'dense_1[26][0]']               \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1, 64)        0           ['activation[0][0]',             \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[1][0]',             \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[2][0]',             \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[3][0]',             \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[4][0]',             \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[5][0]',             \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[6][0]',             \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[7][0]',             \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[8][0]',             \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[9][0]',             \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[10][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[11][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[12][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[13][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[14][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[15][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[16][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[17][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[18][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[19][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[20][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[21][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[22][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[23][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[24][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[25][0]',            \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'activation[26][0]',            \n",
      "                                                                  'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " c0 (InputLayer)                [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 64),         33024       ['dot[0][0]',                    \n",
      "                                 (None, 64),                      's0[0][0]',                     \n",
      "                                 (None, 64)]                      'c0[0][0]',                     \n",
      "                                                                  'dot[1][0]',                    \n",
      "                                                                  'lstm[0][0]',                   \n",
      "                                                                  'lstm[0][2]',                   \n",
      "                                                                  'dot[2][0]',                    \n",
      "                                                                  'lstm[1][0]',                   \n",
      "                                                                  'lstm[1][2]',                   \n",
      "                                                                  'dot[3][0]',                    \n",
      "                                                                  'lstm[2][0]',                   \n",
      "                                                                  'lstm[2][2]',                   \n",
      "                                                                  'dot[4][0]',                    \n",
      "                                                                  'lstm[3][0]',                   \n",
      "                                                                  'lstm[3][2]',                   \n",
      "                                                                  'dot[5][0]',                    \n",
      "                                                                  'lstm[4][0]',                   \n",
      "                                                                  'lstm[4][2]',                   \n",
      "                                                                  'dot[6][0]',                    \n",
      "                                                                  'lstm[5][0]',                   \n",
      "                                                                  'lstm[5][2]',                   \n",
      "                                                                  'dot[7][0]',                    \n",
      "                                                                  'lstm[6][0]',                   \n",
      "                                                                  'lstm[6][2]',                   \n",
      "                                                                  'dot[8][0]',                    \n",
      "                                                                  'lstm[7][0]',                   \n",
      "                                                                  'lstm[7][2]',                   \n",
      "                                                                  'dot[9][0]',                    \n",
      "                                                                  'lstm[8][0]',                   \n",
      "                                                                  'lstm[8][2]',                   \n",
      "                                                                  'dot[10][0]',                   \n",
      "                                                                  'lstm[9][0]',                   \n",
      "                                                                  'lstm[9][2]',                   \n",
      "                                                                  'dot[11][0]',                   \n",
      "                                                                  'lstm[10][0]',                  \n",
      "                                                                  'lstm[10][2]',                  \n",
      "                                                                  'dot[12][0]',                   \n",
      "                                                                  'lstm[11][0]',                  \n",
      "                                                                  'lstm[11][2]',                  \n",
      "                                                                  'dot[13][0]',                   \n",
      "                                                                  'lstm[12][0]',                  \n",
      "                                                                  'lstm[12][2]',                  \n",
      "                                                                  'dot[14][0]',                   \n",
      "                                                                  'lstm[13][0]',                  \n",
      "                                                                  'lstm[13][2]',                  \n",
      "                                                                  'dot[15][0]',                   \n",
      "                                                                  'lstm[14][0]',                  \n",
      "                                                                  'lstm[14][2]',                  \n",
      "                                                                  'dot[16][0]',                   \n",
      "                                                                  'lstm[15][0]',                  \n",
      "                                                                  'lstm[15][2]',                  \n",
      "                                                                  'dot[17][0]',                   \n",
      "                                                                  'lstm[16][0]',                  \n",
      "                                                                  'lstm[16][2]',                  \n",
      "                                                                  'dot[18][0]',                   \n",
      "                                                                  'lstm[17][0]',                  \n",
      "                                                                  'lstm[17][2]',                  \n",
      "                                                                  'dot[19][0]',                   \n",
      "                                                                  'lstm[18][0]',                  \n",
      "                                                                  'lstm[18][2]',                  \n",
      "                                                                  'dot[20][0]',                   \n",
      "                                                                  'lstm[19][0]',                  \n",
      "                                                                  'lstm[19][2]',                  \n",
      "                                                                  'dot[21][0]',                   \n",
      "                                                                  'lstm[20][0]',                  \n",
      "                                                                  'lstm[20][2]',                  \n",
      "                                                                  'dot[22][0]',                   \n",
      "                                                                  'lstm[21][0]',                  \n",
      "                                                                  'lstm[21][2]',                  \n",
      "                                                                  'dot[23][0]',                   \n",
      "                                                                  'lstm[22][0]',                  \n",
      "                                                                  'lstm[22][2]',                  \n",
      "                                                                  'dot[24][0]',                   \n",
      "                                                                  'lstm[23][0]',                  \n",
      "                                                                  'lstm[23][2]',                  \n",
      "                                                                  'dot[25][0]',                   \n",
      "                                                                  'lstm[24][0]',                  \n",
      "                                                                  'lstm[24][2]',                  \n",
      "                                                                  'dot[26][0]',                   \n",
      "                                                                  'lstm[25][0]',                  \n",
      "                                                                  'lstm[25][2]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 33)           2145        ['lstm[0][0]',                   \n",
      "                                                                  'lstm[1][0]',                   \n",
      "                                                                  'lstm[2][0]',                   \n",
      "                                                                  'lstm[3][0]',                   \n",
      "                                                                  'lstm[4][0]',                   \n",
      "                                                                  'lstm[5][0]',                   \n",
      "                                                                  'lstm[6][0]',                   \n",
      "                                                                  'lstm[7][0]',                   \n",
      "                                                                  'lstm[8][0]',                   \n",
      "                                                                  'lstm[9][0]',                   \n",
      "                                                                  'lstm[10][0]',                  \n",
      "                                                                  'lstm[11][0]',                  \n",
      "                                                                  'lstm[12][0]',                  \n",
      "                                                                  'lstm[13][0]',                  \n",
      "                                                                  'lstm[14][0]',                  \n",
      "                                                                  'lstm[15][0]',                  \n",
      "                                                                  'lstm[16][0]',                  \n",
      "                                                                  'lstm[17][0]',                  \n",
      "                                                                  'lstm[18][0]',                  \n",
      "                                                                  'lstm[19][0]',                  \n",
      "                                                                  'lstm[20][0]',                  \n",
      "                                                                  'lstm[21][0]',                  \n",
      "                                                                  'lstm[22][0]',                  \n",
      "                                                                  'lstm[23][0]',                  \n",
      "                                                                  'lstm[24][0]',                  \n",
      "                                                                  'lstm[25][0]',                  \n",
      "                                                                  'lstm[26][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 53,366\n",
      "Trainable params: 53,366\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "XH03tVDP0-nO"
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate= 0.005, beta_1= 0.9, beta_2= 0.999, decay= 0.01)\n",
    "\n",
    "model.compile(optimizer= opt, loss= 'categorical_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "yaUkimVd1cOV"
   },
   "outputs": [],
   "source": [
    "# initialize inputs\n",
    "\n",
    "s0 = np.zeros((x_train.shape[0], n_s))\n",
    "c0 = np.zeros((x_train.shape[0], n_s))\n",
    "outputs = list(y_train.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_j_Vd-uX1vTK",
    "outputId": "ef7fdd86-4e0a-47c5-f73a-50f67231849b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6608/6608 [==============================] - 1098s 158ms/step - loss: 2.1942 - dense_2_loss: 0.0362 - dense_2_1_loss: 0.0309 - dense_2_2_loss: 0.0204 - dense_2_3_loss: 0.0147 - dense_2_4_loss: 0.0269 - dense_2_5_loss: 0.0478 - dense_2_6_loss: 0.0739 - dense_2_7_loss: 0.2889 - dense_2_8_loss: 0.5373 - dense_2_9_loss: 0.4660 - dense_2_10_loss: 0.1803 - dense_2_11_loss: 0.0449 - dense_2_12_loss: 0.0806 - dense_2_13_loss: 0.1088 - dense_2_14_loss: 0.0865 - dense_2_15_loss: 0.0378 - dense_2_16_loss: 0.0100 - dense_2_17_loss: 0.0062 - dense_2_18_loss: 0.0078 - dense_2_19_loss: 0.0103 - dense_2_20_loss: 0.0103 - dense_2_21_loss: 0.0100 - dense_2_22_loss: 0.0140 - dense_2_23_loss: 0.0181 - dense_2_24_loss: 0.0163 - dense_2_25_loss: 0.0080 - dense_2_26_loss: 0.0015 - dense_2_accuracy: 0.9969 - dense_2_1_accuracy: 0.9963 - dense_2_2_accuracy: 0.9974 - dense_2_3_accuracy: 0.9976 - dense_2_4_accuracy: 0.9945 - dense_2_5_accuracy: 0.9827 - dense_2_6_accuracy: 0.9750 - dense_2_7_accuracy: 0.8813 - dense_2_8_accuracy: 0.7675 - dense_2_9_accuracy: 0.7935 - dense_2_10_accuracy: 0.9198 - dense_2_11_accuracy: 0.9877 - dense_2_12_accuracy: 0.9786 - dense_2_13_accuracy: 0.9721 - dense_2_14_accuracy: 0.9796 - dense_2_15_accuracy: 0.9916 - dense_2_16_accuracy: 0.9977 - dense_2_17_accuracy: 0.9985 - dense_2_18_accuracy: 0.9979 - dense_2_19_accuracy: 0.9970 - dense_2_20_accuracy: 0.9970 - dense_2_21_accuracy: 0.9973 - dense_2_22_accuracy: 0.9960 - dense_2_23_accuracy: 0.9942 - dense_2_24_accuracy: 0.9948 - dense_2_25_accuracy: 0.9975 - dense_2_26_accuracy: 0.9996 - val_loss: 2.0140 - val_dense_2_loss: 0.0321 - val_dense_2_1_loss: 0.0245 - val_dense_2_2_loss: 0.0179 - val_dense_2_3_loss: 0.0105 - val_dense_2_4_loss: 0.0212 - val_dense_2_5_loss: 0.0435 - val_dense_2_6_loss: 0.0650 - val_dense_2_7_loss: 0.2709 - val_dense_2_8_loss: 0.5133 - val_dense_2_9_loss: 0.4466 - val_dense_2_10_loss: 0.1717 - val_dense_2_11_loss: 0.0353 - val_dense_2_12_loss: 0.0683 - val_dense_2_13_loss: 0.0939 - val_dense_2_14_loss: 0.0719 - val_dense_2_15_loss: 0.0304 - val_dense_2_16_loss: 0.0076 - val_dense_2_17_loss: 0.0049 - val_dense_2_18_loss: 0.0063 - val_dense_2_19_loss: 0.0088 - val_dense_2_20_loss: 0.0086 - val_dense_2_21_loss: 0.0081 - val_dense_2_22_loss: 0.0127 - val_dense_2_23_loss: 0.0178 - val_dense_2_24_loss: 0.0134 - val_dense_2_25_loss: 0.0070 - val_dense_2_26_loss: 0.0016 - val_dense_2_accuracy: 0.9975 - val_dense_2_1_accuracy: 0.9972 - val_dense_2_2_accuracy: 0.9983 - val_dense_2_3_accuracy: 0.9982 - val_dense_2_4_accuracy: 0.9961 - val_dense_2_5_accuracy: 0.9838 - val_dense_2_6_accuracy: 0.9802 - val_dense_2_7_accuracy: 0.8903 - val_dense_2_8_accuracy: 0.7793 - val_dense_2_9_accuracy: 0.8003 - val_dense_2_10_accuracy: 0.9215 - val_dense_2_11_accuracy: 0.9904 - val_dense_2_12_accuracy: 0.9827 - val_dense_2_13_accuracy: 0.9759 - val_dense_2_14_accuracy: 0.9838 - val_dense_2_15_accuracy: 0.9935 - val_dense_2_16_accuracy: 0.9984 - val_dense_2_17_accuracy: 0.9989 - val_dense_2_18_accuracy: 0.9983 - val_dense_2_19_accuracy: 0.9973 - val_dense_2_20_accuracy: 0.9971 - val_dense_2_21_accuracy: 0.9976 - val_dense_2_22_accuracy: 0.9963 - val_dense_2_23_accuracy: 0.9943 - val_dense_2_24_accuracy: 0.9955 - val_dense_2_25_accuracy: 0.9979 - val_dense_2_26_accuracy: 0.9995\n",
      "Epoch 2/5\n",
      "6608/6608 [==============================] - 1021s 155ms/step - loss: 1.9791 - dense_2_loss: 0.0351 - dense_2_1_loss: 0.0282 - dense_2_2_loss: 0.0189 - dense_2_3_loss: 0.0132 - dense_2_4_loss: 0.0240 - dense_2_5_loss: 0.0448 - dense_2_6_loss: 0.0654 - dense_2_7_loss: 0.2658 - dense_2_8_loss: 0.5078 - dense_2_9_loss: 0.4451 - dense_2_10_loss: 0.1666 - dense_2_11_loss: 0.0297 - dense_2_12_loss: 0.0599 - dense_2_13_loss: 0.0867 - dense_2_14_loss: 0.0691 - dense_2_15_loss: 0.0289 - dense_2_16_loss: 0.0069 - dense_2_17_loss: 0.0044 - dense_2_18_loss: 0.0056 - dense_2_19_loss: 0.0077 - dense_2_20_loss: 0.0080 - dense_2_21_loss: 0.0077 - dense_2_22_loss: 0.0116 - dense_2_23_loss: 0.0157 - dense_2_24_loss: 0.0144 - dense_2_25_loss: 0.0068 - dense_2_26_loss: 0.0012 - dense_2_accuracy: 0.9970 - dense_2_1_accuracy: 0.9969 - dense_2_2_accuracy: 0.9977 - dense_2_3_accuracy: 0.9978 - dense_2_4_accuracy: 0.9954 - dense_2_5_accuracy: 0.9835 - dense_2_6_accuracy: 0.9793 - dense_2_7_accuracy: 0.8931 - dense_2_8_accuracy: 0.7816 - dense_2_9_accuracy: 0.8016 - dense_2_10_accuracy: 0.9242 - dense_2_11_accuracy: 0.9924 - dense_2_12_accuracy: 0.9845 - dense_2_13_accuracy: 0.9784 - dense_2_14_accuracy: 0.9845 - dense_2_15_accuracy: 0.9942 - dense_2_16_accuracy: 0.9986 - dense_2_17_accuracy: 0.9989 - dense_2_18_accuracy: 0.9985 - dense_2_19_accuracy: 0.9978 - dense_2_20_accuracy: 0.9977 - dense_2_21_accuracy: 0.9978 - dense_2_22_accuracy: 0.9965 - dense_2_23_accuracy: 0.9949 - dense_2_24_accuracy: 0.9952 - dense_2_25_accuracy: 0.9978 - dense_2_26_accuracy: 0.9996 - val_loss: 1.9622 - val_dense_2_loss: 0.0318 - val_dense_2_1_loss: 0.0238 - val_dense_2_2_loss: 0.0178 - val_dense_2_3_loss: 0.0105 - val_dense_2_4_loss: 0.0206 - val_dense_2_5_loss: 0.0430 - val_dense_2_6_loss: 0.0629 - val_dense_2_7_loss: 0.2665 - val_dense_2_8_loss: 0.5064 - val_dense_2_9_loss: 0.4413 - val_dense_2_10_loss: 0.1693 - val_dense_2_11_loss: 0.0309 - val_dense_2_12_loss: 0.0620 - val_dense_2_13_loss: 0.0864 - val_dense_2_14_loss: 0.0676 - val_dense_2_15_loss: 0.0287 - val_dense_2_16_loss: 0.0073 - val_dense_2_17_loss: 0.0047 - val_dense_2_18_loss: 0.0061 - val_dense_2_19_loss: 0.0081 - val_dense_2_20_loss: 0.0080 - val_dense_2_21_loss: 0.0076 - val_dense_2_22_loss: 0.0120 - val_dense_2_23_loss: 0.0172 - val_dense_2_24_loss: 0.0134 - val_dense_2_25_loss: 0.0069 - val_dense_2_26_loss: 0.0014 - val_dense_2_accuracy: 0.9975 - val_dense_2_1_accuracy: 0.9973 - val_dense_2_2_accuracy: 0.9983 - val_dense_2_3_accuracy: 0.9981 - val_dense_2_4_accuracy: 0.9961 - val_dense_2_5_accuracy: 0.9840 - val_dense_2_6_accuracy: 0.9808 - val_dense_2_7_accuracy: 0.8932 - val_dense_2_8_accuracy: 0.7835 - val_dense_2_9_accuracy: 0.8030 - val_dense_2_10_accuracy: 0.9221 - val_dense_2_11_accuracy: 0.9918 - val_dense_2_12_accuracy: 0.9844 - val_dense_2_13_accuracy: 0.9783 - val_dense_2_14_accuracy: 0.9847 - val_dense_2_15_accuracy: 0.9942 - val_dense_2_16_accuracy: 0.9985 - val_dense_2_17_accuracy: 0.9990 - val_dense_2_18_accuracy: 0.9986 - val_dense_2_19_accuracy: 0.9976 - val_dense_2_20_accuracy: 0.9975 - val_dense_2_21_accuracy: 0.9977 - val_dense_2_22_accuracy: 0.9965 - val_dense_2_23_accuracy: 0.9945 - val_dense_2_24_accuracy: 0.9955 - val_dense_2_25_accuracy: 0.9979 - val_dense_2_26_accuracy: 0.9996\n",
      "Epoch 3/5\n",
      "6608/6608 [==============================] - 1012s 153ms/step - loss: 1.9477 - dense_2_loss: 0.0348 - dense_2_1_loss: 0.0278 - dense_2_2_loss: 0.0188 - dense_2_3_loss: 0.0131 - dense_2_4_loss: 0.0235 - dense_2_5_loss: 0.0444 - dense_2_6_loss: 0.0642 - dense_2_7_loss: 0.2626 - dense_2_8_loss: 0.5038 - dense_2_9_loss: 0.4425 - dense_2_10_loss: 0.1647 - dense_2_11_loss: 0.0275 - dense_2_12_loss: 0.0570 - dense_2_13_loss: 0.0834 - dense_2_14_loss: 0.0666 - dense_2_15_loss: 0.0275 - dense_2_16_loss: 0.0064 - dense_2_17_loss: 0.0041 - dense_2_18_loss: 0.0050 - dense_2_19_loss: 0.0069 - dense_2_20_loss: 0.0073 - dense_2_21_loss: 0.0072 - dense_2_22_loss: 0.0112 - dense_2_23_loss: 0.0153 - dense_2_24_loss: 0.0141 - dense_2_25_loss: 0.0066 - dense_2_26_loss: 0.0012 - dense_2_accuracy: 0.9970 - dense_2_1_accuracy: 0.9970 - dense_2_2_accuracy: 0.9977 - dense_2_3_accuracy: 0.9978 - dense_2_4_accuracy: 0.9955 - dense_2_5_accuracy: 0.9837 - dense_2_6_accuracy: 0.9798 - dense_2_7_accuracy: 0.8948 - dense_2_8_accuracy: 0.7837 - dense_2_9_accuracy: 0.8027 - dense_2_10_accuracy: 0.9248 - dense_2_11_accuracy: 0.9930 - dense_2_12_accuracy: 0.9853 - dense_2_13_accuracy: 0.9793 - dense_2_14_accuracy: 0.9852 - dense_2_15_accuracy: 0.9945 - dense_2_16_accuracy: 0.9987 - dense_2_17_accuracy: 0.9990 - dense_2_18_accuracy: 0.9988 - dense_2_19_accuracy: 0.9982 - dense_2_20_accuracy: 0.9979 - dense_2_21_accuracy: 0.9980 - dense_2_22_accuracy: 0.9966 - dense_2_23_accuracy: 0.9949 - dense_2_24_accuracy: 0.9953 - dense_2_25_accuracy: 0.9978 - dense_2_26_accuracy: 0.9997 - val_loss: 1.9429 - val_dense_2_loss: 0.0317 - val_dense_2_1_loss: 0.0236 - val_dense_2_2_loss: 0.0177 - val_dense_2_3_loss: 0.0104 - val_dense_2_4_loss: 0.0204 - val_dense_2_5_loss: 0.0429 - val_dense_2_6_loss: 0.0624 - val_dense_2_7_loss: 0.2637 - val_dense_2_8_loss: 0.5036 - val_dense_2_9_loss: 0.4397 - val_dense_2_10_loss: 0.1683 - val_dense_2_11_loss: 0.0296 - val_dense_2_12_loss: 0.0603 - val_dense_2_13_loss: 0.0846 - val_dense_2_14_loss: 0.0656 - val_dense_2_15_loss: 0.0277 - val_dense_2_16_loss: 0.0068 - val_dense_2_17_loss: 0.0045 - val_dense_2_18_loss: 0.0059 - val_dense_2_19_loss: 0.0074 - val_dense_2_20_loss: 0.0074 - val_dense_2_21_loss: 0.0076 - val_dense_2_22_loss: 0.0120 - val_dense_2_23_loss: 0.0174 - val_dense_2_24_loss: 0.0135 - val_dense_2_25_loss: 0.0067 - val_dense_2_26_loss: 0.0014 - val_dense_2_accuracy: 0.9975 - val_dense_2_1_accuracy: 0.9974 - val_dense_2_2_accuracy: 0.9983 - val_dense_2_3_accuracy: 0.9981 - val_dense_2_4_accuracy: 0.9963 - val_dense_2_5_accuracy: 0.9842 - val_dense_2_6_accuracy: 0.9809 - val_dense_2_7_accuracy: 0.8955 - val_dense_2_8_accuracy: 0.7848 - val_dense_2_9_accuracy: 0.8041 - val_dense_2_10_accuracy: 0.9226 - val_dense_2_11_accuracy: 0.9925 - val_dense_2_12_accuracy: 0.9848 - val_dense_2_13_accuracy: 0.9783 - val_dense_2_14_accuracy: 0.9852 - val_dense_2_15_accuracy: 0.9945 - val_dense_2_16_accuracy: 0.9986 - val_dense_2_17_accuracy: 0.9991 - val_dense_2_18_accuracy: 0.9987 - val_dense_2_19_accuracy: 0.9979 - val_dense_2_20_accuracy: 0.9976 - val_dense_2_21_accuracy: 0.9979 - val_dense_2_22_accuracy: 0.9966 - val_dense_2_23_accuracy: 0.9945 - val_dense_2_24_accuracy: 0.9955 - val_dense_2_25_accuracy: 0.9978 - val_dense_2_26_accuracy: 0.9996\n",
      "Epoch 4/5\n",
      "6608/6608 [==============================] - 1008s 153ms/step - loss: 1.9305 - dense_2_loss: 0.0347 - dense_2_1_loss: 0.0277 - dense_2_2_loss: 0.0187 - dense_2_3_loss: 0.0131 - dense_2_4_loss: 0.0233 - dense_2_5_loss: 0.0442 - dense_2_6_loss: 0.0635 - dense_2_7_loss: 0.2606 - dense_2_8_loss: 0.5016 - dense_2_9_loss: 0.4410 - dense_2_10_loss: 0.1638 - dense_2_11_loss: 0.0266 - dense_2_12_loss: 0.0556 - dense_2_13_loss: 0.0817 - dense_2_14_loss: 0.0652 - dense_2_15_loss: 0.0269 - dense_2_16_loss: 0.0061 - dense_2_17_loss: 0.0039 - dense_2_18_loss: 0.0046 - dense_2_19_loss: 0.0064 - dense_2_20_loss: 0.0068 - dense_2_21_loss: 0.0069 - dense_2_22_loss: 0.0110 - dense_2_23_loss: 0.0151 - dense_2_24_loss: 0.0139 - dense_2_25_loss: 0.0065 - dense_2_26_loss: 0.0011 - dense_2_accuracy: 0.9970 - dense_2_1_accuracy: 0.9970 - dense_2_2_accuracy: 0.9978 - dense_2_3_accuracy: 0.9978 - dense_2_4_accuracy: 0.9956 - dense_2_5_accuracy: 0.9837 - dense_2_6_accuracy: 0.9802 - dense_2_7_accuracy: 0.8959 - dense_2_8_accuracy: 0.7850 - dense_2_9_accuracy: 0.8031 - dense_2_10_accuracy: 0.9251 - dense_2_11_accuracy: 0.9933 - dense_2_12_accuracy: 0.9858 - dense_2_13_accuracy: 0.9796 - dense_2_14_accuracy: 0.9855 - dense_2_15_accuracy: 0.9947 - dense_2_16_accuracy: 0.9988 - dense_2_17_accuracy: 0.9991 - dense_2_18_accuracy: 0.9989 - dense_2_19_accuracy: 0.9984 - dense_2_20_accuracy: 0.9982 - dense_2_21_accuracy: 0.9981 - dense_2_22_accuracy: 0.9967 - dense_2_23_accuracy: 0.9950 - dense_2_24_accuracy: 0.9954 - dense_2_25_accuracy: 0.9979 - dense_2_26_accuracy: 0.9997 - val_loss: 1.9328 - val_dense_2_loss: 0.0316 - val_dense_2_1_loss: 0.0235 - val_dense_2_2_loss: 0.0177 - val_dense_2_3_loss: 0.0104 - val_dense_2_4_loss: 0.0201 - val_dense_2_5_loss: 0.0427 - val_dense_2_6_loss: 0.0618 - val_dense_2_7_loss: 0.2625 - val_dense_2_8_loss: 0.5024 - val_dense_2_9_loss: 0.4391 - val_dense_2_10_loss: 0.1678 - val_dense_2_11_loss: 0.0294 - val_dense_2_12_loss: 0.0600 - val_dense_2_13_loss: 0.0840 - val_dense_2_14_loss: 0.0650 - val_dense_2_15_loss: 0.0275 - val_dense_2_16_loss: 0.0067 - val_dense_2_17_loss: 0.0044 - val_dense_2_18_loss: 0.0055 - val_dense_2_19_loss: 0.0068 - val_dense_2_20_loss: 0.0070 - val_dense_2_21_loss: 0.0071 - val_dense_2_22_loss: 0.0116 - val_dense_2_23_loss: 0.0170 - val_dense_2_24_loss: 0.0133 - val_dense_2_25_loss: 0.0066 - val_dense_2_26_loss: 0.0013 - val_dense_2_accuracy: 0.9975 - val_dense_2_1_accuracy: 0.9973 - val_dense_2_2_accuracy: 0.9982 - val_dense_2_3_accuracy: 0.9981 - val_dense_2_4_accuracy: 0.9963 - val_dense_2_5_accuracy: 0.9844 - val_dense_2_6_accuracy: 0.9815 - val_dense_2_7_accuracy: 0.8956 - val_dense_2_8_accuracy: 0.7850 - val_dense_2_9_accuracy: 0.8046 - val_dense_2_10_accuracy: 0.9228 - val_dense_2_11_accuracy: 0.9926 - val_dense_2_12_accuracy: 0.9848 - val_dense_2_13_accuracy: 0.9783 - val_dense_2_14_accuracy: 0.9854 - val_dense_2_15_accuracy: 0.9945 - val_dense_2_16_accuracy: 0.9988 - val_dense_2_17_accuracy: 0.9990 - val_dense_2_18_accuracy: 0.9988 - val_dense_2_19_accuracy: 0.9983 - val_dense_2_20_accuracy: 0.9978 - val_dense_2_21_accuracy: 0.9980 - val_dense_2_22_accuracy: 0.9967 - val_dense_2_23_accuracy: 0.9946 - val_dense_2_24_accuracy: 0.9957 - val_dense_2_25_accuracy: 0.9980 - val_dense_2_26_accuracy: 0.9996\n",
      "Epoch 5/5\n",
      "6608/6608 [==============================] - 1109s 168ms/step - loss: 1.9197 - dense_2_loss: 0.0346 - dense_2_1_loss: 0.0275 - dense_2_2_loss: 0.0187 - dense_2_3_loss: 0.0131 - dense_2_4_loss: 0.0232 - dense_2_5_loss: 0.0440 - dense_2_6_loss: 0.0629 - dense_2_7_loss: 0.2595 - dense_2_8_loss: 0.5003 - dense_2_9_loss: 0.4402 - dense_2_10_loss: 0.1633 - dense_2_11_loss: 0.0260 - dense_2_12_loss: 0.0547 - dense_2_13_loss: 0.0808 - dense_2_14_loss: 0.0643 - dense_2_15_loss: 0.0264 - dense_2_16_loss: 0.0059 - dense_2_17_loss: 0.0038 - dense_2_18_loss: 0.0044 - dense_2_19_loss: 0.0060 - dense_2_20_loss: 0.0064 - dense_2_21_loss: 0.0066 - dense_2_22_loss: 0.0108 - dense_2_23_loss: 0.0149 - dense_2_24_loss: 0.0137 - dense_2_25_loss: 0.0065 - dense_2_26_loss: 0.0011 - dense_2_accuracy: 0.9970 - dense_2_1_accuracy: 0.9971 - dense_2_2_accuracy: 0.9977 - dense_2_3_accuracy: 0.9978 - dense_2_4_accuracy: 0.9956 - dense_2_5_accuracy: 0.9838 - dense_2_6_accuracy: 0.9805 - dense_2_7_accuracy: 0.8963 - dense_2_8_accuracy: 0.7855 - dense_2_9_accuracy: 0.8037 - dense_2_10_accuracy: 0.9253 - dense_2_11_accuracy: 0.9935 - dense_2_12_accuracy: 0.9861 - dense_2_13_accuracy: 0.9799 - dense_2_14_accuracy: 0.9857 - dense_2_15_accuracy: 0.9948 - dense_2_16_accuracy: 0.9989 - dense_2_17_accuracy: 0.9991 - dense_2_18_accuracy: 0.9989 - dense_2_19_accuracy: 0.9986 - dense_2_20_accuracy: 0.9983 - dense_2_21_accuracy: 0.9982 - dense_2_22_accuracy: 0.9967 - dense_2_23_accuracy: 0.9950 - dense_2_24_accuracy: 0.9954 - dense_2_25_accuracy: 0.9979 - dense_2_26_accuracy: 0.9997 - val_loss: 1.9263 - val_dense_2_loss: 0.0315 - val_dense_2_1_loss: 0.0234 - val_dense_2_2_loss: 0.0177 - val_dense_2_3_loss: 0.0104 - val_dense_2_4_loss: 0.0201 - val_dense_2_5_loss: 0.0426 - val_dense_2_6_loss: 0.0613 - val_dense_2_7_loss: 0.2617 - val_dense_2_8_loss: 0.5014 - val_dense_2_9_loss: 0.4388 - val_dense_2_10_loss: 0.1676 - val_dense_2_11_loss: 0.0290 - val_dense_2_12_loss: 0.0596 - val_dense_2_13_loss: 0.0830 - val_dense_2_14_loss: 0.0647 - val_dense_2_15_loss: 0.0270 - val_dense_2_16_loss: 0.0066 - val_dense_2_17_loss: 0.0043 - val_dense_2_18_loss: 0.0055 - val_dense_2_19_loss: 0.0066 - val_dense_2_20_loss: 0.0068 - val_dense_2_21_loss: 0.0071 - val_dense_2_22_loss: 0.0114 - val_dense_2_23_loss: 0.0171 - val_dense_2_24_loss: 0.0133 - val_dense_2_25_loss: 0.0066 - val_dense_2_26_loss: 0.0013 - val_dense_2_accuracy: 0.9975 - val_dense_2_1_accuracy: 0.9973 - val_dense_2_2_accuracy: 0.9983 - val_dense_2_3_accuracy: 0.9982 - val_dense_2_4_accuracy: 0.9963 - val_dense_2_5_accuracy: 0.9845 - val_dense_2_6_accuracy: 0.9813 - val_dense_2_7_accuracy: 0.8963 - val_dense_2_8_accuracy: 0.7860 - val_dense_2_9_accuracy: 0.8048 - val_dense_2_10_accuracy: 0.9226 - val_dense_2_11_accuracy: 0.9925 - val_dense_2_12_accuracy: 0.9849 - val_dense_2_13_accuracy: 0.9789 - val_dense_2_14_accuracy: 0.9854 - val_dense_2_15_accuracy: 0.9946 - val_dense_2_16_accuracy: 0.9987 - val_dense_2_17_accuracy: 0.9991 - val_dense_2_18_accuracy: 0.9988 - val_dense_2_19_accuracy: 0.9985 - val_dense_2_20_accuracy: 0.9979 - val_dense_2_21_accuracy: 0.9981 - val_dense_2_22_accuracy: 0.9967 - val_dense_2_23_accuracy: 0.9945 - val_dense_2_24_accuracy: 0.9956 - val_dense_2_25_accuracy: 0.9980 - val_dense_2_26_accuracy: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f19fa45fd50>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "model.fit([x_train, s0, c0], outputs, epochs= 5, batch_size= 100, validation_split= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "dhem4zj91zGN"
   },
   "outputs": [],
   "source": [
    "model.save('model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "W_5D9t97ADLJ",
    "outputId": "7e8d448b-4e67-41bb-b687-c3a4f3eb8f3b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dense_2_accuracy</th>\n",
       "      <th>dense_2_1_accuracy</th>\n",
       "      <th>dense_2_2_accuracy</th>\n",
       "      <th>dense_2_3_accuracy</th>\n",
       "      <th>dense_2_4_accuracy</th>\n",
       "      <th>dense_2_5_accuracy</th>\n",
       "      <th>dense_2_6_accuracy</th>\n",
       "      <th>dense_2_7_accuracy</th>\n",
       "      <th>dense_2_8_accuracy</th>\n",
       "      <th>dense_2_9_accuracy</th>\n",
       "      <th>dense_2_10_accuracy</th>\n",
       "      <th>dense_2_11_accuracy</th>\n",
       "      <th>dense_2_12_accuracy</th>\n",
       "      <th>dense_2_13_accuracy</th>\n",
       "      <th>dense_2_14_accuracy</th>\n",
       "      <th>dense_2_15_accuracy</th>\n",
       "      <th>dense_2_16_accuracy</th>\n",
       "      <th>dense_2_17_accuracy</th>\n",
       "      <th>dense_2_18_accuracy</th>\n",
       "      <th>dense_2_19_accuracy</th>\n",
       "      <th>dense_2_20_accuracy</th>\n",
       "      <th>dense_2_21_accuracy</th>\n",
       "      <th>dense_2_22_accuracy</th>\n",
       "      <th>dense_2_23_accuracy</th>\n",
       "      <th>dense_2_24_accuracy</th>\n",
       "      <th>dense_2_25_accuracy</th>\n",
       "      <th>dense_2_26_accuracy</th>\n",
       "      <th>val_dense_2_accuracy</th>\n",
       "      <th>val_dense_2_1_accuracy</th>\n",
       "      <th>val_dense_2_2_accuracy</th>\n",
       "      <th>val_dense_2_3_accuracy</th>\n",
       "      <th>val_dense_2_4_accuracy</th>\n",
       "      <th>val_dense_2_5_accuracy</th>\n",
       "      <th>val_dense_2_6_accuracy</th>\n",
       "      <th>val_dense_2_7_accuracy</th>\n",
       "      <th>val_dense_2_8_accuracy</th>\n",
       "      <th>val_dense_2_9_accuracy</th>\n",
       "      <th>val_dense_2_10_accuracy</th>\n",
       "      <th>val_dense_2_11_accuracy</th>\n",
       "      <th>val_dense_2_12_accuracy</th>\n",
       "      <th>val_dense_2_13_accuracy</th>\n",
       "      <th>val_dense_2_14_accuracy</th>\n",
       "      <th>val_dense_2_15_accuracy</th>\n",
       "      <th>val_dense_2_16_accuracy</th>\n",
       "      <th>val_dense_2_17_accuracy</th>\n",
       "      <th>val_dense_2_18_accuracy</th>\n",
       "      <th>val_dense_2_19_accuracy</th>\n",
       "      <th>val_dense_2_20_accuracy</th>\n",
       "      <th>val_dense_2_21_accuracy</th>\n",
       "      <th>val_dense_2_22_accuracy</th>\n",
       "      <th>val_dense_2_23_accuracy</th>\n",
       "      <th>val_dense_2_24_accuracy</th>\n",
       "      <th>val_dense_2_25_accuracy</th>\n",
       "      <th>val_dense_2_26_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996899</td>\n",
       "      <td>0.996341</td>\n",
       "      <td>0.997406</td>\n",
       "      <td>0.997618</td>\n",
       "      <td>0.994473</td>\n",
       "      <td>0.982725</td>\n",
       "      <td>0.974955</td>\n",
       "      <td>0.881329</td>\n",
       "      <td>0.767544</td>\n",
       "      <td>0.793518</td>\n",
       "      <td>0.919765</td>\n",
       "      <td>0.987666</td>\n",
       "      <td>0.978630</td>\n",
       "      <td>0.972109</td>\n",
       "      <td>0.979627</td>\n",
       "      <td>0.991578</td>\n",
       "      <td>0.997700</td>\n",
       "      <td>0.998455</td>\n",
       "      <td>0.997857</td>\n",
       "      <td>0.997031</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>0.997267</td>\n",
       "      <td>0.996017</td>\n",
       "      <td>0.994236</td>\n",
       "      <td>0.994777</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.999564</td>\n",
       "      <td>0.997499</td>\n",
       "      <td>0.997240</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.998189</td>\n",
       "      <td>0.996147</td>\n",
       "      <td>0.983783</td>\n",
       "      <td>0.980160</td>\n",
       "      <td>0.890336</td>\n",
       "      <td>0.779321</td>\n",
       "      <td>0.800339</td>\n",
       "      <td>0.921476</td>\n",
       "      <td>0.990368</td>\n",
       "      <td>0.982691</td>\n",
       "      <td>0.975905</td>\n",
       "      <td>0.983841</td>\n",
       "      <td>0.993531</td>\n",
       "      <td>0.998390</td>\n",
       "      <td>0.998879</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.997067</td>\n",
       "      <td>0.997613</td>\n",
       "      <td>0.996291</td>\n",
       "      <td>0.994278</td>\n",
       "      <td>0.995457</td>\n",
       "      <td>0.997930</td>\n",
       "      <td>0.999540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997004</td>\n",
       "      <td>0.996929</td>\n",
       "      <td>0.997739</td>\n",
       "      <td>0.997846</td>\n",
       "      <td>0.995351</td>\n",
       "      <td>0.983527</td>\n",
       "      <td>0.979288</td>\n",
       "      <td>0.893115</td>\n",
       "      <td>0.781552</td>\n",
       "      <td>0.801647</td>\n",
       "      <td>0.924175</td>\n",
       "      <td>0.992385</td>\n",
       "      <td>0.984535</td>\n",
       "      <td>0.978441</td>\n",
       "      <td>0.984461</td>\n",
       "      <td>0.994195</td>\n",
       "      <td>0.998552</td>\n",
       "      <td>0.998941</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.997651</td>\n",
       "      <td>0.997834</td>\n",
       "      <td>0.996484</td>\n",
       "      <td>0.994874</td>\n",
       "      <td>0.995247</td>\n",
       "      <td>0.997757</td>\n",
       "      <td>0.999635</td>\n",
       "      <td>0.997499</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.998074</td>\n",
       "      <td>0.996118</td>\n",
       "      <td>0.983956</td>\n",
       "      <td>0.980764</td>\n",
       "      <td>0.893211</td>\n",
       "      <td>0.783519</td>\n",
       "      <td>0.803042</td>\n",
       "      <td>0.922051</td>\n",
       "      <td>0.991777</td>\n",
       "      <td>0.984416</td>\n",
       "      <td>0.978320</td>\n",
       "      <td>0.984703</td>\n",
       "      <td>0.994192</td>\n",
       "      <td>0.998505</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>0.998620</td>\n",
       "      <td>0.997613</td>\n",
       "      <td>0.997470</td>\n",
       "      <td>0.997700</td>\n",
       "      <td>0.996521</td>\n",
       "      <td>0.994508</td>\n",
       "      <td>0.995486</td>\n",
       "      <td>0.997872</td>\n",
       "      <td>0.999569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997040</td>\n",
       "      <td>0.996999</td>\n",
       "      <td>0.997750</td>\n",
       "      <td>0.997825</td>\n",
       "      <td>0.995501</td>\n",
       "      <td>0.983662</td>\n",
       "      <td>0.979795</td>\n",
       "      <td>0.894772</td>\n",
       "      <td>0.783693</td>\n",
       "      <td>0.802742</td>\n",
       "      <td>0.924768</td>\n",
       "      <td>0.993020</td>\n",
       "      <td>0.985316</td>\n",
       "      <td>0.979266</td>\n",
       "      <td>0.985171</td>\n",
       "      <td>0.994544</td>\n",
       "      <td>0.998726</td>\n",
       "      <td>0.999042</td>\n",
       "      <td>0.998756</td>\n",
       "      <td>0.998199</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.997995</td>\n",
       "      <td>0.996595</td>\n",
       "      <td>0.994915</td>\n",
       "      <td>0.995334</td>\n",
       "      <td>0.997822</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>0.997383</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>0.998102</td>\n",
       "      <td>0.996291</td>\n",
       "      <td>0.984215</td>\n",
       "      <td>0.980937</td>\n",
       "      <td>0.895483</td>\n",
       "      <td>0.784813</td>\n",
       "      <td>0.804135</td>\n",
       "      <td>0.922568</td>\n",
       "      <td>0.992467</td>\n",
       "      <td>0.984790</td>\n",
       "      <td>0.978263</td>\n",
       "      <td>0.985221</td>\n",
       "      <td>0.994508</td>\n",
       "      <td>0.998591</td>\n",
       "      <td>0.999051</td>\n",
       "      <td>0.998677</td>\n",
       "      <td>0.997901</td>\n",
       "      <td>0.997613</td>\n",
       "      <td>0.997872</td>\n",
       "      <td>0.996578</td>\n",
       "      <td>0.994508</td>\n",
       "      <td>0.995515</td>\n",
       "      <td>0.997844</td>\n",
       "      <td>0.999597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997044</td>\n",
       "      <td>0.997029</td>\n",
       "      <td>0.997756</td>\n",
       "      <td>0.997837</td>\n",
       "      <td>0.995598</td>\n",
       "      <td>0.983722</td>\n",
       "      <td>0.980245</td>\n",
       "      <td>0.895910</td>\n",
       "      <td>0.784987</td>\n",
       "      <td>0.803105</td>\n",
       "      <td>0.925128</td>\n",
       "      <td>0.993337</td>\n",
       "      <td>0.985782</td>\n",
       "      <td>0.979621</td>\n",
       "      <td>0.985502</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.998823</td>\n",
       "      <td>0.999087</td>\n",
       "      <td>0.998900</td>\n",
       "      <td>0.998441</td>\n",
       "      <td>0.998187</td>\n",
       "      <td>0.998114</td>\n",
       "      <td>0.996669</td>\n",
       "      <td>0.994974</td>\n",
       "      <td>0.995396</td>\n",
       "      <td>0.997863</td>\n",
       "      <td>0.999676</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.998217</td>\n",
       "      <td>0.998131</td>\n",
       "      <td>0.996348</td>\n",
       "      <td>0.984387</td>\n",
       "      <td>0.981454</td>\n",
       "      <td>0.895627</td>\n",
       "      <td>0.784985</td>\n",
       "      <td>0.804566</td>\n",
       "      <td>0.922769</td>\n",
       "      <td>0.992553</td>\n",
       "      <td>0.984818</td>\n",
       "      <td>0.978349</td>\n",
       "      <td>0.985393</td>\n",
       "      <td>0.994537</td>\n",
       "      <td>0.998821</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>0.998821</td>\n",
       "      <td>0.998332</td>\n",
       "      <td>0.997844</td>\n",
       "      <td>0.998016</td>\n",
       "      <td>0.996665</td>\n",
       "      <td>0.994594</td>\n",
       "      <td>0.995687</td>\n",
       "      <td>0.997959</td>\n",
       "      <td>0.999597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997049</td>\n",
       "      <td>0.997072</td>\n",
       "      <td>0.997748</td>\n",
       "      <td>0.997822</td>\n",
       "      <td>0.995628</td>\n",
       "      <td>0.983774</td>\n",
       "      <td>0.980461</td>\n",
       "      <td>0.896337</td>\n",
       "      <td>0.785529</td>\n",
       "      <td>0.803728</td>\n",
       "      <td>0.925293</td>\n",
       "      <td>0.993515</td>\n",
       "      <td>0.986101</td>\n",
       "      <td>0.979934</td>\n",
       "      <td>0.985697</td>\n",
       "      <td>0.994827</td>\n",
       "      <td>0.998915</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.998942</td>\n",
       "      <td>0.998558</td>\n",
       "      <td>0.998308</td>\n",
       "      <td>0.998182</td>\n",
       "      <td>0.996687</td>\n",
       "      <td>0.995033</td>\n",
       "      <td>0.995439</td>\n",
       "      <td>0.997880</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.998189</td>\n",
       "      <td>0.996348</td>\n",
       "      <td>0.984502</td>\n",
       "      <td>0.981339</td>\n",
       "      <td>0.896259</td>\n",
       "      <td>0.785963</td>\n",
       "      <td>0.804796</td>\n",
       "      <td>0.922597</td>\n",
       "      <td>0.992524</td>\n",
       "      <td>0.984933</td>\n",
       "      <td>0.978924</td>\n",
       "      <td>0.985422</td>\n",
       "      <td>0.994594</td>\n",
       "      <td>0.998735</td>\n",
       "      <td>0.999080</td>\n",
       "      <td>0.998764</td>\n",
       "      <td>0.998476</td>\n",
       "      <td>0.997930</td>\n",
       "      <td>0.998074</td>\n",
       "      <td>0.996722</td>\n",
       "      <td>0.994451</td>\n",
       "      <td>0.995601</td>\n",
       "      <td>0.997987</td>\n",
       "      <td>0.999626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dense_2_accuracy  ...  val_dense_2_26_accuracy\n",
       "0          0.996899  ...                 0.999540\n",
       "1          0.997004  ...                 0.999569\n",
       "2          0.997040  ...                 0.999597\n",
       "3          0.997044  ...                 0.999597\n",
       "4          0.997049  ...                 0.999626\n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check accuracies evolutions through epochs of training\n",
    "\n",
    "x = [title for title in model.history.history.keys() if 'accuracy' in title]\n",
    "\n",
    "df = pd.DataFrame(model.history.history)[x]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKs6CwCAKvPp"
   },
   "source": [
    "* We can see that for **each position t** of our output sequence, we are predicting the vocab item with an **accuracy > 0.78**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLwnOboR3LB8"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "36OBUmQSo-DO"
   },
   "outputs": [],
   "source": [
    "model = load_model('model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "dxZ0p91AjUlv"
   },
   "outputs": [],
   "source": [
    "s0 = np.zeros((x_test.shape[0], n_s))\n",
    "c0 = np.zeros((x_test.shape[0], n_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "pPr1DKSoLkkr"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "\n",
    "test_predictions = model.predict([x_test, s0, c0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xqK3tXyOz-0",
    "outputId": "9472c954-ffcb-4aca-eeaf-65995cd2ffcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36609, 27)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from list of lists to array\n",
    "\n",
    "new_test_predictions = np.argmax(test_predictions, axis = -1)\n",
    "\n",
    "new_test_predictions = np.array(new_test_predictions).T\n",
    "\n",
    "new_test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "0NcZEfZTQA19"
   },
   "outputs": [],
   "source": [
    "def index_to_string(indexed_forms):\n",
    "  \"\"\"\n",
    "  converts from indexed sequences to strings\n",
    "  \"\"\"\n",
    "  \n",
    "  forms = []\n",
    "\n",
    "  for row in indexed_forms: \n",
    "\n",
    "    forms.append(''.join([k for index in row for k, v in vocab_dict.items() if v == index]).replace('<pad>', ''))\n",
    "\n",
    "  return forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gucs3vgeplLI",
    "outputId": "b9bb9dd8-8afc-4fe9-82d6-a053df11f810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6*t*(7*t-20) = 42*t**2-120*t  || predicted =====> 42*t**2-120*t\n",
      "(14-6*h)*(-6*h-26) = 36*h**2+72*h-364  || predicted =====> 36*h**2+70*h-364\n",
      "(21-2*c)*(c-21) = -2*c**2+63*c-441  || predicted =====> -2*c**2+65*c-441\n",
      "(a-15)*(a-3) = a**2-18*a+45  || predicted =====> a**2-18*a+45\n",
      "(i+19)*(i+31) = i**2+50*i+589  || predicted =====> i**2+56*i+589\n",
      "(7-9*y)*(4*y-10) = -36*y**2+118*y-70  || predicted =====> -36*y**2+118*y-70\n",
      "(2*i+18)*(4*i-9) = 8*i**2+54*i-162  || predicted =====> 8*i**2+50*i-162\n",
      "(-4*x-22)*(2*x-29) = -8*x**2+72*x+638  || predicted =====> -8*x**2+70*x+638\n",
      "4*a*(31-6*a) = -24*a**2+124*a  || predicted =====> -24*a**2+124*a\n",
      "i*(i-2) = i**2-2*i  || predicted =====> i**2-2*i\n"
     ]
    }
   ],
   "source": [
    "# see some random examples\n",
    "\n",
    "num_test_seqs = x_test.shape[0]\n",
    "\n",
    "random_indexes = np.random.choice(num_test_seqs, 10)\n",
    "\n",
    "x_sample = index_to_string (x_test[random_indexes].argmax(axis= -1))\n",
    "\n",
    "y_sample = index_to_string (y_test[random_indexes].argmax(axis= -1))\n",
    "\n",
    "predicted_sample = index_to_string(new_test_predictions[random_indexes])\n",
    "\n",
    "for i, j, k in zip(x_sample, y_sample, predicted_sample):\n",
    "\n",
    "  print(i, '=', j, ' || predicted =====>', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "RlfLA7L_xNI2"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(predicted_expanded, real_expanded):\n",
    "\n",
    "   accuracy = sum([ i == j for i,j in zip(predicted_expanded,real_expanded)]) / len(predicted_expanded)\n",
    "\n",
    "   return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92xslch6x4_K",
    "outputId": "0a383f45-d212-4b6b-bcc4-95ed75c0d63d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(predicted_sample, y_sample) #index_to_string (y_test[random_indexes].argmax(axis= -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5T3fv4ch51S"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "* Our model performs fine for all **the expanded form positions** with classification accuracies > **0.97**, except for positions **8 and 9** where we score near **0.8**.\n",
    "\n",
    "* This may affect the global accuracy score a little bit because it is measured on sequence-level equality which means that individual classifications errors may reach important levels when accumulating.\n",
    "\n",
    "* We reached this performance by training the model on about **20 epochs** with a high cost of **2h per 5 epochs** that made decreasing the loss even more quite difficult.\n",
    "\n",
    "* A potential improvement of our model is to pursue its training using GPUs or simply more powerful machines. This will also open the opportunity for more hyperparameters tuning and design improvements."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Increase RAM Reference Notes By Techhawa .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
